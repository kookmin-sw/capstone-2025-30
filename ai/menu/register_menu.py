import os
from dotenv import load_dotenv
from pymongo import MongoClient
import gspread
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
import requests
import mimetypes
import boto3
import urllib.parse

from google.auth import default

load_dotenv()
mongo_db_url = os.getenv("MONGO_DB_URL")
client = MongoClient(mongo_db_url)
db = client["dev"]
json_key_file = os.getenv("SPREADSHEET_JSON_KEY")

def register_menu():

    menu_collection = db["menu"]

    menu_collection.insert_one({
        "name": "americano",
        "description": "ê³ ì†Œí•˜ê³  ì€ì€í•œ ë‹¨ë§›ê³¼ ê· í˜•ì¡íŒ ë°¸ëŸ°ìŠ¤ê°€ íŠ¹ì§•",
        "category": "coffee",
        "price": 4000,
    })
    menu_collection.insert_one({
        "name": "cafe_latte",
        "description": "ê³ ì†Œí•œ ì—ìŠ¤í”„ë ˆì†Œì™€ ë¶€ë“œëŸ¬ìš´ ìš°ìœ ê°€ ì–´ìš°ëŸ¬ì§„ ì»¤í”¼ìŒë£Œ",
        "category": "coffee",
        "price": 4500
    })
    menu_collection.insert_one({
        "name": "wild_dry_cappuccino",
        "description": "í’ë¶€í•œ ìš°ìœ  ê±°í’ˆì— ì‹œë‚˜ëª¬ìŠˆê°€ì˜ í–¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•œ ì»¤í”¼ìŒë£Œ",
        "category": "coffee",
        "price": 4500
    })
    menu_collection.insert_one({
        "name": "roasted_almond_latte",
        "description": "ê³ ì†Œí•œ ì•„ëª¬ë“œí–¥ê³¼ ë‹¬ì½¤í•¨ì´ ì–´ìš°ëŸ¬ì§„ ì»¤í”¼ìŒë£Œ",
        "category": "coffee",
        "price": 5000
    })
    menu_collection.insert_one({
        "name": "muscovado_latte",
        "description": "ìœ ê¸°ë† ì‚¬íƒ•ìˆ˜ìˆ˜ë‹¹ì„ ì‚¬ìš©í•œ íŠ¹ë³„í•œ ìˆ™ì„±ë°€í¬ì™€ ì»¤í”¼ë¥¼ ë°°í•©í•œ ê³ ì†Œí•˜ê³  ë¬µì§í•œ ì¹´í˜ë¼ë–¼",
        "category": "coffee",
        "price": 5000
    })
    menu_collection.insert_one({
        "name": "brown_sugar_macchiato",
        "description": "ê³ ìœ ì˜ ê¹Šì€ í’ë¯¸ë¥¼ ê°€ì§„ ëŒ€ë§Œì‚° ë¸Œë¼ìš´ ìŠˆê°€ê°€ ë“œë¦¬ì¦ ëœ ë‹¬ì½¤í•œ ì»¤í”¼",
        "category": "coffee",
        "price": 5000
    })
    menu_collection.insert_one({
        "name": "jeju_green_oat_latte",
        "description": "ì–´ë¦°ì°»ììœ¼ë¡œ ë§Œë“  ì œì£¼ì‚° ìµœê³ ê¸‰ ë§ì°¨ì™€ ê·€ë¦¬ìš°ìœ ë¥¼ ë°°í•©í•œ ê³ ì†Œí•˜ê³  ì§„í•œ ë§ì°¨ë¼ë–¼",
        "category": "beverage",
        "price": 5000
    })
    menu_collection.insert_one({
        "name": "sweet_coffee",
        "description": "ë¹„ì •ì œ ì„¤íƒ•ìœ¼ë¡œ ë§Œë“  ë² ì´ìŠ¤ì— ì˜¬ë¼ê°„ í•˜ê²ë‹¤ì¦ˆ ì•„ì´ìŠ¤í¬ë¦¼ì€ ë§ˆìŒì´ ì €ì¶•ë¨ì„ í‘œí˜„í•˜ì˜€ìœ¼ë©° ì»¤í”¼ì™€ ë§Œë‚˜ ì‚¬ë¥´ë¥´ ë…¹ëŠ” ë‹¬ì½¤í•¨ìœ¼ë¡œ ë§ˆë¬´ë¦¬ ë©ë‹ˆë‹¤.",
        "category": "signature",
        "price": 6500
    })
    menu_collection.insert_one({
        "name": "piggybank_choco_latte",
        "description": "ì–´ë ·ì„ ì  ë‚˜ë§Œì˜ ê¸ˆê³ ì˜€ë˜ ë¼ì§€ ì €ê¸ˆí†µì˜ ê°ì„±ì„ ë™ì „ ì´ˆì½œë¦¿ìœ¼ë¡œ í‘œí˜„í•œ ê°ì„±ì  ìŒë£Œì…ë‹ˆë‹¤.",
        "category": "signature",
        "price": 6000
    })
    menu_collection.insert_one({
        "name": "bank_schpanner",
        "description": "ë‹¬ì½¤í•˜ê³  ì«€ë“í•œ ìƒí¬ë¦¼ì´ ì˜¬ë¼ê°„ ì•„ì¸ìŠˆí˜ë„ˆë¡œì„œ ì ì‹œì˜ íœ´ì‹ì´ í•„ìš”í•œ ìˆœê°„ ì€í–‰ë„ ì¹´í˜ê°€ ë©ë‹ˆë‹¤.",
        "category": "signature",
        "price": 5500
    })
    menu_collection.insert_one({
        "name": "elderflower_ade",
        "description": "ì—˜ë”í”Œë¼ì›Œì˜ ì€ì€í•œ í–¥ì´ ëŠê»´ì§€ëŠ” ì‹ìš©ê½ƒìœ¼ë¡œ ì¥ì‹í•œ ì²­ëŸ‰í•œ ì—ì´ë“œ",
        "category": "ice_drinks",
        "price": 5500
    })
    menu_collection.insert_one({
        "name": "passion_berry_ade",
        "description": "ìƒí¼í•œ ë¼ì¦ˆë² ë¦¬ì™€ ë‹¬ì½¤í•œ ë¸”ë£¨ë² ë¦¬ ë² ì´ìŠ¤ì˜ ì²­ëŸ‰í•œ ì—ì´ë“œ",
        "category": "ice_drinks",
        "price": 5500
    })
    menu_collection.insert_one({
        "name": "cafe_coco_and_shot_smoothie",
        "description": "ë‹¬ì½¤í•œ ì½”ì½”ë„› ë¸”ë Œë””ë“œì— ìŠ¤ìœ—ì˜ ì—ìŠ¤í”„ë ˆì†Œë¥¼ í”Œë¡œíŒ…í•œ ì»¤í”¼ ìŠ¤ë¬´ë””",
        "category": "ice_drinks",
        "price": 5500
    })
    menu_collection.insert_one({
        "name": "plain_yogurt_smoothie",
        "description": "ë‹¬ì½¤í•œ ìš”ê±°íŠ¸ ë§›ì´ í’ë¶€í•œ ë¶€ë“œëŸ¬ìš´ ë¸”ë Œë””ë“œ ìŒë£Œ",
        "category": "ice_drinks",
        "price": 5500
    })
    menu_collection.insert_one({
        "name": "berry_yogurt_smoothie",
        "description": "ìƒí¼í•œ ë¼ì¦ˆë² ë¦¬ì™€ ë‹¬ì½¤í•œ ë¸”ë£¨ë² ë¦¬ ë² ì´ìŠ¤ë¥¼ ì´ìš©í•œ ìš”ê±°íŠ¸ ë¸”ë Œë””ë“œ ìŒë£Œ",
        "category": "ice_drinks",
        "price": 5500
    })
    menu_collection.insert_one({
        "name": "verveine_orange_mint",
        "description": "ë²„ë² ë‚˜, ì˜¤ë Œì§€, ë¯¼íŠ¸ê°€ ë¶€ë“œëŸ½ê²Œ ë¸”ë Œë”©ëœ ì„¬ì„¸í•œ í—ˆë¸Œ ë¸”ë Œë”© í‹°",
        "category": "tea",
        "price": 4500
    })
    menu_collection.insert_one({
        "name": "rooibos_de_vanille",
        "description": "í”„ë¦¬ë¯¸ì—„ ë£¨ì´ë³´ìŠ¤ì— ë°”ë‹ë¼ì™€ ì•„ëª¬ë“œê°€ ë”í•´ì ¸ ë‹¬ì½¤í•˜ë©´ì„œ í¬ê·¼í•œ ëŠë‚Œì„ ì£¼ëŠ” ë…¼ì¹´í˜ì¸ í‹°",
        "category": "tea",
        "price": 4500
    })
    menu_collection.insert_one({
        "name": "blue_of_london",
        "description": "ë² ë¥´ê°€ì˜· í–¥ê³¼ ì‚°ëœ»í•œ ì˜¤ë Œì§€ í–¥ì„ ë”í•œ ì—¬ìš´ê³¼ ë°”ë””ê°ì´ í’ë¶€í•œ ë¸”ë Œë”© í™ì°¨",
        "category": "tea",
        "price": 4500
    })
    menu_collection.insert_one({
        "name": "chamomile_apple_spicy",
        "description": "ìºëª¨ë§ˆì¼, ì‚¬ê³¼ ìŠ¤íŒŒì´ìŠ¤ í—ˆë¸Œë¥¼ ë¸”ë Œë”©í•˜ì—¬ ë”°ëœ»í•¨ê³¼ í¸ì•ˆí•¨ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” í—ˆë¸Œ ë¸”ë Œë”© í‹°",
        "category": "tea",
        "price": 4500
    })

    print("menu ì»¬ë ‰ì…˜ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

# register_menu()

def update_sign_language_description():

    menu_collection = db["menu"]

    descriptions = {
        "americano": "ì»¤í”¼, ì§„í•˜ë‹¤, ì“°ë‹¤, ìš°ìœ , ì—†ë‹¤, ë‹¹, ì•½í•˜ë‹¤",
        "cafe_latte": "ìš°ìœ , ì»¤í”¼, ë¶€ë“œëŸ½ë‹¤, ë„£ë‹¤",
        "wild_dry_cappuccino": "ì»¤í”¼, ìš°ìœ , ë¶€í’€ë‹¤, ì»¤í”¼, ì„ë‹¤, ë¶€ë“œëŸ½ë‹¤, í–¥ê¸°, ë‹¹, ì¢‹ë‹¤",
        "roasted_almond_latte": "ì»¤í”¼, í˜¸ë‘, í–¥ê¸°, ì¢‹ë‹¤, ë‹¹, ì„ë‹¤, ë§ˆì‹œë‹¤",
        "muscovado_latte": "ìš°ìœ , ì„±ìˆ™, ë‹¹, ì‚¬ìš©, íŠ¹ë³„, ì»¤í”¼, ì„ë‹¤, ë§›, ê¹Šë‹¤, ë¬´ê²ë‹¤, ë§ˆì‹œë‹¤",
        "brown_sugar_macchiato": "ã„·, ã…, ã…, ã…, ã„´, ë‹¹, ê°ˆìƒ‰, ìœ„, ë¿Œë¦¬ë‹¤, ë‹¹, ì»¤í”¼, ë§›, ê¹Šë‹¤",
        "jeju_green_oat_latte": "ë…¹ì°¨, ìš°ìœ , ã„±, ã…Ÿ, ã„¹, ã…£, ì„ë‹¤, ë§›, ì¢‹ë‹¤, ì§„í•˜ë‹¤, ë§ˆì‹œë‹¤",
        "sweet_coffee": "ìœ„, ì•„ì´ìŠ¤í¬ë¦¼, ì»¤í”¼, í•¨ê»˜, ë…¹ë‹¤, ë¶€ë“œëŸ½ë‹¤, ë‹¬ë‹¤",
        "piggybank_choco_latte": "ã…Š, ì½”, ìš°ìœ , ë„£ë‹¤, ë¶€ë“œëŸ½ë‹¤, ë‹¬ë‹¤",
        "bank_schpanner": "ìƒí¬ë¦¼, ìœ„, ë‹¬ë‹¤, ë¶€ë“œëŸ½ë‹¤, ì»¤í”¼, ì„ë‹¤, ë¶€ë“œëŸ½ë‹¤",
        "elderflower_ade": "ê½ƒ, ã…‡, ã…”, ã„¹, í–¥ê¸°, ì¢‹ë‹¤, ê½ƒ, ë¨¹ë‹¤, ì˜ˆì˜ë‹¤, ê³¼ì¼, ë§ˆì‹œë‹¤, ì‹œì›í•˜ë‹¤, ì¢‹ë‹¤",
        "passion_berry_ade": "ê³¼ì¼, ã„¹, ã…, ã…ˆ, ì‹œë‹¤, ì¢‹ë‹¤, ê³¼ì¼, ã…‚, ã„¹, ã…œ, ë‹¬ë‹¤, ì„ë‹¤, ë§ˆì‹œë‹¤, ì‹œì›í•˜ë‹¤",
        "cafe_coco_and_shot_smoothie": "ê³¼ì¼, ã…‹, ã…—, ë‹¬ë‹¤, ì–¼ìŒ, ê°ˆë‹¤, ì„ë‹¤, ì»¤í”¼, ì§„í•˜ë‹¤, ìœ„, ë§ˆì‹œë‹¤, ì‹œì›í•˜ë‹¤",
        "plain_yogurt_smoothie": "ìš°ìœ , ã…‡, ã…›, ë‹¬ë‹¤, ë§›, ì§„í•˜ë‹¤, ë¶€ë“œëŸ½ë‹¤, ì–¼ìŒ, ê°ˆë‹¤, ì„ë‹¤, ë§ˆì‹œë‹¤",
        "berry_yogurt_smoothie": "ê³¼ì¼, ã„¹, ã…, ã…ˆ, ì‹œë‹¤, ê³¼ì¼, ã…‚, ã„¹, ã…œ, ë‹¬ë‹¤, ìš°ìœ , ã…‡, ã…›, ì–¼ìŒ, ê°ˆë‹¤, ì„ë‹¤, ë§ˆì‹œë‹¤",
        "verveine_orange_mint": "ã…, ã…“, ã…‚, í–¥ê¸°, ì¢‹ë‹¤, ê³¼ì¼, ì‹œë‹¤, ë¶€ë“œëŸ½ë‹¤, ì„ë‹¤, ì°¨, ë§ˆì‹œë‹¤, ì‹œì›í•˜ë‹¤",
        "rooibos_de_vanille": "ì°¨, ã„¹, ã…œ, ã…‡, ë‹¬ë‹¤, í–¥ê¸°, ì¢‹ë‹¤, ë¶€ë“œëŸ½ë‹¤, í˜¸ë‘, ë§ˆì‹œë‹¤",
        "blue_of_london": "í–¥ê¸°, ì¢‹ë‹¤, ê³¼ì¼, ì‹œë‹¤, í–¥ê¸°, ì¢‹ë‹¤, ì§„í•˜ë‹¤, ë¬´ê²ë‹¤, ë§ë‹¤, ì„ë‹¤, ã…, ã…—, ã…‡, ì°¨, ë§ˆì‹œë‹¤",
        "chamomile_apple_spicy": "ã…‹, ã…, ã…, ê½ƒ, ì‚¬ê³¼, ë§›, ì§„í•˜ë‹¤, ê½ƒ, í–¥ê¸°, ë¨¹ë‹¤, ì„ë‹¤, ì°¨, ë”°ëœ»í•˜ë‹¤, í¸í•˜ë‹¤, ëŠë¼ë‹¤"
    }

    for name, desc in descriptions.items():
        menu_collection.update_one(
            {"name": name}, {"$set": {"sign_language_description": desc}}
        )

    print("ëª¨ë“  ë©”ë‰´ì— sign_language_description í•„ë“œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")



# update_sign_language_description()

def register_sign_language_words():
    sign_language_collection = db["sign_language"]

    creds = Credentials.from_service_account_file(json_key_file, scopes=[
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ])
    gc = gspread.authorize(creds)
    spreadsheet_id = os.getenv("SPREADSHEET_ID")
    spreadsheet = gc.open_by_key(spreadsheet_id)
    sheet = spreadsheet.get_worksheet_by_id(859465925)  

    # ì „ì²´ í–‰ì„ ì‚½ì…í•˜ëŠ” ê²½ìš°
    data = sheet.get_all_records()

    print(data)
    # sign_language_collection.insert_many(data)

    # headers = sheet.row_values(1)

    # ë‹¨ì¼ í–‰ì„ ì‚½ì…í•˜ëŠ” ê²½ìš°
    # row_new = sheet.row_values(71)

    # if row_new:
    #     data_new = dict(zip(headers, row_new))

    #     sign_language_collection.insert_one(data_new)

    # ì—¬ëŸ¬ í–‰ì„ ì‚½ì…í•˜ëŠ” ê²½ìš°
    # rows_new = sheet.get(f"A72:Z74")  

    # if rows_new:
    #     data_list = [dict(zip(headers, row)) for row in rows_new]  

    #     sign_language_collection.insert_many(data_list) 
    print("sign_language ë°ì´í„°ê°€ MongoDBì— ì‚½ì…ë˜ì—ˆìŠµë‹ˆë‹¤.")


# register_sign_language_words()

def download_sign_language_urls():

    creds = Credentials.from_service_account_file(json_key_file, scopes=[
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ])
    gc = gspread.authorize(creds)
    spreadsheet_id = os.getenv("SPREADSHEET_ID")
    folder_id = "1ChqG-GqfKEFwddkq5x3SeLqMNUIa-UYc"
    sheet = gc.open_by_key(spreadsheet_id).sheet1
    records = sheet.get_all_records()

    drive_service = build('drive', 'v3', credentials=creds)

    for row in records:
        name = row['name']
        url = row['url']
        download_and_upload_video(url, name, folder_id, drive_service)

def download_and_upload_video(url, filename, folder_id, drive_service):
    
    response = requests.get(url)
    if response.status_code == 200:
        ext = mimetypes.guess_extension(response.headers['Content-Type'])
        if not ext:
            ext = ".mp4"  
        local_path = f"{filename}{ext}"

        with open(local_path, 'wb') as f:
            f.write(response.content)

        file_metadata = {
            'name': os.path.basename(local_path),
            'parents': [folder_id]
        }
        media = MediaFileUpload(local_path, resumable=True)
        uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()
        print(f"Uploaded: {filename} (ID: {uploaded_file['id']})")

        os.remove(local_path) 
    else:
        print(f"Failed to download: {url}")


def download_sign_language_urls():
    creds = Credentials.from_service_account_file(json_key_file, scopes=[
        "https://www.googleapis.com/auth/spreadsheets"
    ])
    gc = gspread.authorize(creds)
    spreadsheet_id = os.getenv("SPREADSHEET_ID")
    sheet = gc.open_by_key(spreadsheet_id).sheet1
    records = sheet.get_all_records()

    s3_bucket_name = os.getenv("S3_BUCKET_NAME")

    for row in records[174:]:
        name = row['name']
        url = row['url']
        download_and_upload_video(url, name, s3_bucket_name)

def download_and_upload_video(url, filename, bucket_name):
    response = requests.get(url)
    if response.status_code == 200:
        ext = mimetypes.guess_extension(response.headers.get('Content-Type', 'video/mp4'))
        if not ext:
            ext = ".mp4"
        local_path = f"{filename}{ext}"

        with open(local_path, 'wb') as f:
            f.write(response.content)

        s3 = boto3.client('s3')
        s3.upload_file(local_path, bucket_name, os.path.basename(local_path),ExtraArgs={
        'ContentType': 'video/mp4',
        'ContentDisposition': 'inline'
    })
        print(f"Uploaded to S3: {filename}")

        os.remove(local_path)
    else:
        print(f"Failed to download: {url}")

# download_sign_language_urls()

def find_missing_uploaded_files():
    creds = Credentials.from_service_account_file(json_key_file, scopes=[
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ])
    gc = gspread.authorize(creds)
    spreadsheet_id = os.getenv("SPREADSHEET_ID")
    folder_id = "1ChqG-GqfKEFwddkq5x3SeLqMNUIa-UYc"

    sheet = gc.open_by_key(spreadsheet_id).sheet1
    records = sheet.get_all_records()
    expected_names = set(row['name'] for row in records if row['name'])

    drive_service = build('drive', 'v3', credentials=creds)

    uploaded_files = []
    page_token = None
    while True:
        response = drive_service.files().list(
            q=f"'{folder_id}' in parents",
            spaces='drive',
            fields='nextPageToken, files(name)',
            pageToken=page_token
        ).execute()
        uploaded_files.extend([file['name'].replace('.mp4', '') for file in response.get('files', [])])
        page_token = response.get('nextPageToken', None)
        if page_token is None:
            break

    uploaded_set = set(uploaded_files)

    missing = expected_names - uploaded_set

    print("\nğŸ” ëˆ„ë½ëœ ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡:")
    for name in missing:
        print(f" - {name}")

    return missing

# find_missing_uploaded_files()

def reregister_sign_language_urls():
    creds = Credentials.from_service_account_file(json_key_file, scopes=[
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ])
    gc = gspread.authorize(creds)
    spreadsheet_id = os.getenv("SPREADSHEET_ID")
    folder_id = "1ChqG-GqfKEFwddkq5x3SeLqMNUIa-UYc"

    spreadsheet = gc.open_by_key(spreadsheet_id)
    sheet = spreadsheet.get_worksheet_by_id(859465925)  

    drive_service = build('drive', 'v3', credentials=creds)

    query = f"'{folder_id}' in parents"
    files = []
    page_token = None
    while True:
        response = drive_service.files().list(
            q=query,
            fields="nextPageToken, files(id, name)",
            pageToken=page_token
        ).execute()
        files.extend(response.get('files', []))
        page_token = response.get('nextPageToken', None)
        if page_token is None:
            break

    data = [['name', 'url']]
    for file in files:
        file_id = file['id']
        name = os.path.splitext(file['name'])[0] 

        drive_service.permissions().create(
            fileId=file_id,
            body={'type': 'anyone', 'role': 'reader'},
            fields='id'
        ).execute()

        share_url = f"https://drive.google.com/file/d/{file_id}/view?usp=sharing"
        data.append([name, share_url])
        print(f"{name} â†’ {share_url}")

    sheet.clear()
    sheet.update("A1", data)

    print("âœ… .mp4 ì œê±° ì™„ë£Œ í›„ ì‹œíŠ¸ì— ê³µìœ  ë§í¬ ì €ì¥ë¨")

def reregister_sign_language_urls():
    creds = Credentials.from_service_account_file(json_key_file, scopes=[
        "https://www.googleapis.com/auth/spreadsheets"
    ])
    gc = gspread.authorize(creds)
    spreadsheet_id = os.getenv("SPREADSHEET_ID")
    sheet = gc.open_by_key(spreadsheet_id).get_worksheet_by_id(859465925)

    # S3 ì •ë³´
    s3_bucket = os.getenv("S3_BUCKET_NAME") 
    s3_prefix = ""
    s3 = boto3.client("s3", region_name="ap-northeast-2") 

    base_url = f"https://{s3_bucket}.s3.ap-northeast-2.amazonaws.com"

    response = s3.list_objects_v2(Bucket=s3_bucket, Prefix=s3_prefix)
    objects = response.get("Contents", [])

    data = [['name', 'url']]
    for obj in objects:
        key = obj["Key"]
        if key.endswith("/"):
            continue
        filename = os.path.basename(key)
        name = os.path.splitext(filename)[0]

        encoded_key = urllib.parse.quote(key)
        object_url = f"{base_url}/{encoded_key}"

        data.append([name, object_url])
        print(f"{name} â†’ {object_url}")

    sheet.clear()
    sheet.update("A1", data)
    print("âœ… ì„œìš¸ ë¦¬ì „ ê¸°ë°˜ URLì„ í¼ì„¼íŠ¸ ì¸ì½”ë”© í›„ ì‹œíŠ¸ì— ì €ì¥ ì™„ë£Œ")

# reregister_sign_language_urls()


def register_avatar_sign_language_words():
    sign_language_collection = db["avatar_sign_language"]

    creds = Credentials.from_service_account_file(json_key_file, scopes=[
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ])
    gc = gspread.authorize(creds)
    spreadsheet_id = os.getenv("SPREADSHEET_ID")

    spreadsheet = gc.open_by_key(spreadsheet_id)
    # sheet = spreadsheet.get_worksheet(1)
    sheet = spreadsheet.worksheet("ì•„ë°”íƒ€ì‹œíŠ¸") 

    data = sheet.get_all_records()
    sign_language_collection.insert_many(data)

    print("avatar sign_language ë°ì´í„°ê°€ mongo DBì— ì‚½ì… ë˜ì—ˆìŠµë‹ˆë‹¤.")

# register_avatar_sign_language_words()


def get_sign_language_url_list(menu):
    menu_collection = db["menu"]
    sign_language_collection = db["sign_language"]

    menu_data = menu_collection.find_one({"name": menu}, {"sign_language_description": 1})

    if not menu_data or "sign_language_description" not in menu_data:
        print(f"{menu} ë©”ë‰´ì— ëŒ€í•œ sign_language_descriptionì´ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    words = menu_data["sign_language_description"].split(", ")

    url_list = []
    for word in words:
        sign_data = sign_language_collection.find_one({"name": {"$regex": word}})

        if sign_data and "url" in sign_data:
            url_list.append(sign_data["url"])

    return url_list

# print(get_sign_language_url_list("americano"))


def add_sign_language_urls():
    menu_collection = db["menu"]
    
    # ë©”ë‰´ ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´
    menus = menu_collection.find({}, {"name": 1})
    
    for menu in menus:
        menu_name = menu["name"]
        
        url = get_sign_language_url_list(menu_name)
        
        menu_collection.update_one(
            {"name": menu_name}, 
            {"$set": {"sign_language_urls": url}}
        )

# add_sign_language_urls()
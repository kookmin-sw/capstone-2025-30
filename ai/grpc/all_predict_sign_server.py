import grpc
from concurrent import futures
import tensorflow as tf
import json
import numpy as np
import mediapipe as mp
import os
from tensorflow.keras.layers import Layer
import tensorflow as tf
import all_predict_sign_pb2
import all_predict_sign_pb2_grpc
import load_to_korean_rag
import load_to_sign_rag

class Attention(Layer):
    def __init__(self, **kwargs): 
        super(Attention, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name="attention_weight", shape=(input_shape[-1], 1),
                                 initializer="normal")
        self.b = self.add_weight(name="attention_bias", shape=(input_shape[1], 1),
                                 initializer="zeros")
        super(Attention, self).build(input_shape)

    def call(self, x):
        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)
        a = tf.keras.backend.softmax(e, axis=1)
        output = x * a
        return tf.keras.backend.sum(output, axis=1)

env = os.getenv('APP_ENV', 'local')

if env == "production":
    model = tf.keras.models.load_model(
        'models/60_v22_masked_angles.keras',
        custom_objects={'Attention': Attention}
    )
else:
    model = tf.keras.models.load_model(
    '../models/60_v22_masked_angles.keras',
    custom_objects={
        'Attention': Attention,
    }
    )


def focal_loss(gamma=2.0, alpha=0.25):
    def loss(y_true, y_pred):
        y_pred = tf.clip_by_value(y_pred, 1e-9, 1.0)  # log(0) ë°©ì§€
        cross_entropy = -y_true * tf.math.log(y_pred)
        weight = alpha * tf.pow(1 - y_pred, gamma)
        return tf.reduce_mean(tf.reduce_sum(weight * cross_entropy, axis=-1))
    return loss

if env == 'production':
    path = 'gesture_dict/60_v22_pad_gesture_dict.json'
else:
    path = '../gesture_dict/60_v22_pad_gesture_dict.json'

with open(path, 'r', encoding='utf-8') as f:
    gesture_dict = json.load(f)

actions = [gesture_dict[str(i)] for i in range(len(gesture_dict))]

mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2)


class SignAIService(all_predict_sign_pb2_grpc.SignAIServicer):
    def PredictFromFrames(self, request, context):
        joint_data_list = request.frames
        store_id = request.store_id
        fps = request.fps
        video_frames_length = request.video_length
        video_length = video_frames_length / fps

        if len(joint_data_list) < 60 * 78:
            return all_predict_sign_pb2.PredictResult(
                store_id=store_id,
                predicted_sentence="ìµœì†Œ 60í”„ë ˆìž„ì€ í•„ìš”í•©ë‹ˆë‹¤!",
                confidence=0.0
            )
        
        confidence_threshold = 0.81
        stationary_threshold = 0.02  
        min_stationary_frames = int(fps * 0.8) 
        seq_length = 60
        feature_dim = 78

        full_data = np.array(joint_data_list).reshape(-1, feature_dim)
        total_frames = full_data.shape[0]

        motion_segments = []
        start_frame = 0
        stationary_count = 0

        for i in range(1, total_frames):
            diff = np.linalg.norm(full_data[i] - full_data[i - 1])
            if diff < stationary_threshold:
                stationary_count += 1
            else:
                if stationary_count >= min_stationary_frames:
                    end_frame = i - stationary_count
                    if end_frame - start_frame >= seq_length:
                        motion_segments.append((start_frame, end_frame))
                    start_frame = i
                stationary_count = 0

        if total_frames - start_frame >= seq_length:
            motion_segments.append((start_frame, total_frames))

        sentences = []
        confidences = []

        for start_frame, end_frame in motion_segments:
            segment = full_data[start_frame:end_frame]

            for i in range(0, len(segment) - seq_length + 1, seq_length):
                input_data = segment[i:i + seq_length]

                pred = model.predict(np.expand_dims(input_data, axis=0), verbose=0)
                pred_label = np.argmax(pred[0])
                predicted_sentence = actions[pred_label]
                confidence = float(pred[0][pred_label])

                if "," in predicted_sentence:
                    predicted_sentence = predicted_sentence.split(",")[0]
                    if predicted_sentence == "ë‹¹ë¶€":
                        predicted_sentence = "ìš”ì²­"

                if start_frame == 1 and (predicted_sentence == "ë§ˆì‹œë‹¤" or predicted_sentence == "ë¹„ë°€"):
                    continue

                if confidence < confidence_threshold:
                    continue

                if predicted_sentence == "ê¸°ê³„":
                    predicted_sentence = "í‚¤ì˜¤ìŠ¤í¬"

                sentences.append(predicted_sentence)
                confidences.append(confidence)
                print(f"Motion Segment @ Frame {start_frame}: Sentence: {predicted_sentence}, Confidence: {confidence:.4f}")

        if not sentences:
            return all_predict_sign_pb2.PredictResult(
                store_id=store_id,
                predicted_sentence="No valid segments",
                confidence=0.0
            )

        final_sentence = ' '.join(sentences)
        final_sentence = load_to_korean_rag.get_translate_from_sign_language(final_sentence)
        avg_confidence = float(np.mean(confidences))

        print(final_sentence)

        return all_predict_sign_pb2.PredictResult(
            store_id=store_id,
            predicted_sentence=final_sentence,
            confidence=avg_confidence
        )



    def TranslateKoreanToSignUrls(self, request, context):
        inqury = request.message
        store_id = request.store_id

        urls = load_to_sign_rag.get_sign_language_url_list(inqury)

        return all_predict_sign_pb2.SignUrlResult(
            store_id=store_id,
            urls=urls
        )

def load_tls_credentials():
    certificate_chain = os.environ['AI_TLS_CRT'].encode('utf-8')
    private_key = os.environ['AI_TLS_KEY'].encode('utf-8')

    return grpc.ssl_server_credentials(
        [(private_key, certificate_chain)],
        root_certificates=None,
        require_client_auth=False
    )

def serve():
    try:
        server = grpc.server(futures.ThreadPoolExecutor(max_workers=10),
                             options=[('grpc.max_send_message_length', 10 * 1024 * 1024),
                                      ('grpc.max_receive_message_length', 10 * 1024 * 1024)])
        all_predict_sign_pb2_grpc.add_SignAIServicer_to_server(SignAIService(), server)
        
        if env == "production":
            creds = load_tls_credentials()
            print("âœ… TLS ì¸ì¦ì„œ ë¡œë“œ ì„±ê³µ")
            port_result = server.add_secure_port('[::]:50051', creds)
        else:
            port_result = server.add_insecure_port('[::]:50051')
        
        print(f"âœ… í¬íŠ¸ ë°”ì¸ë”© ê²°ê³¼: {port_result}")
        
        print("ðŸš€ AI ì„œë²„ ì‹¤í–‰ ì¤‘... í¬íŠ¸: 50051")
        server.start()
        server.wait_for_termination()

    except Exception as e:
        print("âŒ ì„œë²„ ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ:", e)

if __name__ == '__main__':
    print("ðŸš€ ë©”ì¸ìœ¼ë¡œ ì‹¤í–‰ë¨")
    serve()

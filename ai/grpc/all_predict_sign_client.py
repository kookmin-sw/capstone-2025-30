import cv2
import grpc
import os
import all_predict_sign_pb2
import all_predict_sign_pb2_grpc
import numpy as np
import mediapipe as mp
import json

from dotenv import load_dotenv
import os

load_dotenv()
host = os.getenv("AI_EC2_HOST")
env = os.getenv('APP_ENV', 'local')
trusted_certs = os.environ['AI_TLS_CRT'].encode('utf-8')
credentials = grpc.ssl_channel_credentials(root_certificates=trusted_certs)

if env == 'production':
    channel = grpc.secure_channel(f"{host}:50051",
                                credentials,
                                    options=[('grpc.max_send_message_length', 10 * 1024 * 1024),
                                            ('grpc.max_receive_message_length', 10 * 1024 * 1024)]) 
else :
    channel = grpc.insecure_channel(f"localhost:50051",
                                    options=[('grpc.max_send_message_length', 10 * 1024 * 1024), 
                                             ('grpc.max_receive_message_length', 10 * 1024 * 1024)])

stub = all_predict_sign_pb2_grpc.SignAIStub(channel)

# --- ì˜ìƒ ì—´ê¸° ---

"""
ì˜ ë§ì¶¤
- í¬í¬ì™€ íœ´ì§€ì˜ ê²½ìš° ë‹¨ì–´ ë‹¨ì¼ë¡œ ì˜ˆì¸¡ë  ê²½ìš° ìë™ìœ¼ë¡œ "ê°€ ìˆë‚˜ìš”"ë¥¼ ë¶™ì´ê²Œ í•˜ë“œì½”ë”©í•¨
"""
# video_path = 'í‚¤ì˜¤ìŠ¤í¬ ì£¼ë¬¸ì´ ì–´ë ¤ìš´ë° ë„ì™€ì£¼ì„¸ìš”.mp4'
# video_path = 'ì˜ìˆ˜ì¦ ì£¼ì„¸ìš”.mp4'
# video_path = 'ë”°ëœ»í•˜ê²Œ í•´ì£¼ì„¸ìš”.mp4'
# video_path = 'í™”ì¥ì‹¤ ë¹„ë°€ë²ˆí˜¸ ìˆë‚˜ìš”?.mp4'
# video_path = 'íœ´ì§€ ìˆì–´ìš”_.mp4'
# video_path = 'í¬í¬ê°€ ìˆì–´ìš”_.mp4'
# video_path = 'ì•„ë©”ë¦¬ì¹´ë…¸_ìˆ˜ì–´í†µí•©ë³¸.mp4'
# video_path = 'ê¸ì •.mp4'


# video_path = 'ê¸°2.mp4'
# video_path = 'í™”2.mp4'
# video_path = "í™”_1ì´ˆì¶”ê°€_8.mp4"
# video_path = "ì˜_1ì´ˆì¶”ê°€.mp4"
# video_path = "ê¸1.mp4"
# video_path = "êµ_1ì´ˆì¶”ê°€_2.mp4"
# video_path = 'ë”°_1ì´ˆì¶”ê°€_6.mp4'
# video_path = "ì_1ì´ˆì¶”ê°€.mp4"
video_path = ""


"""
ì•½ê°„ì˜ ì†ì‹¤ - ì˜ë¯¸ ìœ ì¶” ê°€ëŠ¥
"""
# video_path = "ì°¨_1ì´ˆì¶”ê°€_2.mp4"
# video_path = 'ê¸°_1ì´ˆì¶”ê°€.mp4'

"""
ì¹˜ëª…ì  ì†ì‹¤ - ì˜ë¯¸ ìœ ì¶” ì• ë§¤
v9 
- ì¹´ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì˜¤ìŠ¤í¬ì—ì„œ ê²°ì œí•˜ë‹¤
- ì§€íë¥¼ í¬ì¥í•´ ì£¼ì„¸ìš”
"""
# video_path = 'í• ì¸ì¹´ë“œ ì‚¬ìš©í•˜ê³  ì‹¶ì–´ìš”.mp4'
# video_path = 'í˜„ê¸ˆê²°ì œ ì›í•´ìš”.mp4'
# video_path = 'í˜„1.mp4'
# video_path = "í• _1ì´ˆì¶”ê°€.mp4"

"""
í•œ ë‹¨ì–´ë§Œ ë§ì¶¤ - ì˜ë¯¸ ìœ ì¶” ë¶ˆê°€ëŠ¥
"""
# video_path = "http://sldict.korean.go.kr/multimedia/multimedia_files/convert/20200825/735712/MOV000240883_700X466.mp4"
# video_path = 'í¬ì¸íŠ¸ê°€ ìˆë‚˜ìš”?.mp4'
# video_path = "ëœ ë‹¬ê²Œ í•´ì£¼ì„¸ìš”.mp4"
# video_path = "ëœ2.mp4"
# video_path = "í¬_1ì´ˆì¶”ê°€.mp4"

"""
ì „í˜€ ì•ˆë¨ - ì˜ë¯¸ ìœ ì¶” ë¶ˆê°€ëŠ¥
"""
# video_path = "ëˆ1.mp4"
# video_path = 'í™˜1.mp4'

cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print("âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

fps = cap.get(cv2.CAP_PROP_FPS)
frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
print(f"ë¹„ë””ì˜¤ FPS: {fps}")


# --- Mediapipe ì´ˆê¸°í™” ---
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2)

def compute_angles(joints_63):
    joints = joints_63.reshape(-1, 21, 3)
    seq_out = []

    for joint in joints:
        v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :]
        v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :]
        v = v2 - v1
        v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]

        angle = np.arccos(np.einsum('nt,nt->n',
            v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], 
            v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:]
        ))
        angle = np.degrees(angle)
        feature = np.concatenate([joint.flatten(), angle])
        seq_out.append(feature)

    return np.array(seq_out)

# --- í”„ë ˆì„ ë¶„ì„ ---
joint_data_list = []

while True:
    ret, frame = cap.read()
    if not ret:
        break

    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(img_rgb)

    if result.multi_hand_landmarks:
        for res in result.multi_hand_landmarks:
            joint = np.zeros((21, 3))
            for j, lm in enumerate(res.landmark):
                joint[j] = [lm.x, lm.y, lm.z]

            joint_data_list.append(joint.flatten())

cap.release()
hands.close()

print(f"ğŸ“Œ ì¶”ì¶œëœ ì† ì¢Œí‘œ ê°œìˆ˜: {len(joint_data_list)}")

joints_np = np.array(joint_data_list) 
angles = compute_angles(joints_np)  

flat_joints = angles.flatten().tolist()  

request = all_predict_sign_pb2.FrameSequenceInput(
    frames=flat_joints,
    store_id="store_object_id",
    fps=int(fps),
    video_length=frame_count
)

response = stub.PredictFromFrames(request)
print(f"[ê²°ê³¼] Store: {response.store_id}, ë¬¸ì¥: {response.predicted_sentence}, Confidence: {response.confidence:.4f}")


# # --- For Postman ---
# request_data = {
#     "store_id": "store_object_id",
#     "fps": int(fps),
#     "video_length": frame_count,
#     "frames": flat_joints,
# }

# with open("ì°¨2.json", "w", encoding="utf-8") as f:
#     json.dump(request_data, f, ensure_ascii=False, indent=2)

# print("âœ… JSON ì €ì¥ ì™„ë£Œ: frame_sequence_input.json")